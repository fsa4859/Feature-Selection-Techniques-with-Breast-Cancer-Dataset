# -*- coding: utf-8 -*-
"""Untitled32.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zzqDEFk6J6Yhf3oM_glwfryLAbFKRYkh

This notebook uses scikit learn libraries to help in the feature selction process
"""

# first load the data 
import numpy as np
import pandas as pd

df=pd.read_csv("/content/data.csv")

df.head()

# check the datatypes
df.dtypes

# check the existence of null values
df.isna().sum()

# find the shape of the df
df.shape,len(df)

# remove the column ID and unnamed
cols_to_remove=['Unnamed: 32','id']

df.drop(cols_to_remove,axis=1,inplace=True)

df.head()

# The output of this problem is the diagnosis col

df['diagnosis'].unique(), df['diagnosis'].count()

# change the diagnosis column to have values between 0 and 1
df['diagnosis']=df['diagnosis'].replace(['M','B'],[1,0])

df['diagnosis']

# now we will split the data into indpendent features and dependent features
X=df.drop(['diagnosis'],axis=1)
Y=df['diagnosis']

X.head(),Y.head()

len(X),len(Y)

# fit the model and calculate different matrices

# first we will import the required libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFE, SelectKBest, SelectFromModel, chi2, f_classif
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score
from sklearn.svm import LinearSVC
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt

# create a function for fitting the model

def fit_model(x,y):

  model=RandomForestClassifier(criterion='entropy',
                               random_state=47)
  
  model.fit(x,y)

  return model

def calculate_metrics(model,x_test_scaled,y_test):

  # get the model predicitons
  y_predict=model.predict(x_test_scaled)
  # calculate different evaluation metrics
  roc=roc_auc_score(y_test,y_predict)
  acc=accuracy_score(y_test,y_predict)
  prec=precision_score(y_test,y_predict)
  recallscore=recall_score(y_test,y_predict)
  f1=f1_score(y_test,y_predict)

  return roc,acc,prec,recallscore,f1

def train_and_get_metrics(X,Y):

  X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,
                                                 stratify=Y,random_state=123)
  

  # we normalize all the features
  scaler=StandardScaler().fit(X_train)
  X_train_sclaed=scaler.transform(X_train)
  X_test_scaled=scaler.transform(X_test)

  # call the fit model
  model=fit_model(X_train_sclaed,Y_train)

  # make predictions on test dataset and calculate metrics
  roc, acc, prec, rec, f1 = calculate_metrics(model, X_test_scaled, Y_test)

  return acc, roc, prec, rec, f1

def evaluate_model_on_features(X,Y):

  acc, roc, prec, rec, f1 = train_and_get_metrics(X, Y)

  # Construct a dataframe to display metrics
  df_display=pd.DataFrame([[acc,roc,prec,rec,f1,X.shape[1]]],columns=["Accuracy",
                                                                      "ROC",
                                                                      "Precision",
                                                                      "Recall",
                                                                      "F1 Score",
                                                                      "Feature Count"])
  
  return df_display

# calculate evaluation metrics

all_features_eval_df=evaluate_model_on_features(X,Y)

all_features_eval_df.index=['All Features']

results=all_features_eval_df

results.head()

# plot the correlation matrix

plt.figure(figsize=(20,20))

# calculate correlation matrix
corr=df.corr()

# plot the heatmap
sns.heatmap(corr,annot=True,cmap=plt.cm.PuBu)
plt.show()

"""**Correlation by Filter Methods**

1- These methods use statistical ranking of the features regardless of the model to be trained on 

2- Filter methods are performed for one variable in relation to the target variable one at a time and that's why it is called univariate feature_selction

3- There are three methods for filter techniques which are 

a- peason_correlation: The pearson correlation works for numerical features and numerical categories

b- Anova F-test: Works for numerical features and categorical target feature

c- Chi squared: works for categorical features and categorical taregt

**if we are taking into account the target variable, then this is called supervised feature selection**
"""

# using pearson method
cor_target=abs(corr['diagnosis'])

type(cor_target),cor_target

# filter the values that are more than 0.2

relevant_features=cor_target[cor_target>0.2]

relevant_features

# now we will iterate through releavent features (iterating through a series)

for label,content in relevant_features.iteritems():
  print(f'label is {label} and its value is {content}')

# now we collect the names of the features

names=[index for index,value in relevant_features.iteritems()]

names,len(names)

# remove the 'diagnosis' from names
names.remove('diagnosis')

names,len(names)

# now we will evaluate the model on the new features

strong_features_eval_df=evaluate_model_on_features(df[names],Y)

strong_features_eval_df.index=['Strong_Features']

results.append(strong_features_eval_df)

"""**Correlation with other features**

We will then eliminate the other features that are strongly correlated with each other and so we will be removing redundant features. In this case,we are performing unsupervised feature selection since we are not considering the target variables
"""

# visualize the heatmap again

plt.figure(figsize=(20,20))

# calculate the correlation matrix for the target relevant features
new_corr=df[names].corr()

sns.heatmap(new_corr, annot=True, cmap=plt.cm.Blues)
plt.show()

# next we will have a magnified view of the correlation in some features that are
# highly correlated

# Set figure size
plt.figure(figsize=(12,10))

# Select a subset of features
new_corr = df[['perimeter_mean', 'radius_worst', 'perimeter_worst', 'area_worst', 'concave points_mean', 'radius_mean', 'concavity_mean']].corr()

# Visualize the correlation matrix
sns.heatmap(new_corr, annot=True, cmap=plt.cm.Blues)
plt.show()

# remove the redunant features

subset_corr_feature_names=[x for x in names if x not in ['perimeter_mean', 'radius_worst', 'perimeter_worst', 'area_worst', 'concavepoints_mean']]

# subset feature evaluation df

subset_feature_eval_df=evaluate_model_on_features(df[subset_corr_feature_names],Y)

subset_feature_eval_df.index=['subset_features']

results=results.append(subset_feature_eval_df)

results

results=results.drop(0)

results

results.append(strong_features_eval_df)

results.iloc[[0]]

results

results=results.append(strong_features_eval_df)

results

# we can swam subset_features and strong_features

tmp=results.iloc[1]

results.iloc[1]=results.iloc[2]

results.iloc[2]=tmp

results

"""Univariate selection with SciKit Learn

We will use the Anova f test
"""

def univariate_selection():

  # split the train and test sets

  X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=123)
  
  # normalize the features
  scaler = StandardScaler().fit(X_train)
  X_train_scaled = scaler.transform(X_train)
  X_test_scaled = scaler.transform(X_test)

  # select up to 20 features based on f test
  selector=SelectKBest(f_classif,k=20)

  # fit to scaled data and then transform it
  X_new=selector.fit_transform(X_train_scaled,Y_train)

  # get the feature_index
  feature_index=selector.get_support()

  # print the results

  for name,included in zip(df.drop("diagnosis",1).columns,feature_index):
    print("%s: %s" % (name, included))
  
  feature_names = df.drop("diagnosis",1 ).columns[feature_index]
    
  return feature_names

univariate_feature_names=univariate_selection()

univariate_eval_df=evaluate_model_on_features(df[univariate_feature_names],Y)

univariate_eval_df.index=['F Test']

results=results.append(univariate_eval_df)

results.head(n=10)

"""**Wrapper Methods**

Wrappr Methods uses a model to evaluate the effectivenss of the selected features. In the forward type, you add features until no improvements are acheived. In the backward selection, we remove features until model degrades in performance.

Recursive Feature Elimination: the recursive feature elimination is similar to the backward elimination except that it evaluates the features based on the importance

**Recursive Feature Elimination**
"""

def run_rfe():

  X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,
                                                 random_state=123)
  
  # normalize
  scaler=StandardScaler().fit(X_train)
  X_train_scaled=scaler.fit_transform(X_train)
  X_test_scaled=scaler.fit_transform(X_test)

  # define the model
  model=RandomForestClassifier(criterion='entropy',
                               random_state=47)
  
  # wrap rfe around the model
  rfe=RFE(model,n_features_to_select=20)

  # fit the rfe
  rfe=rfe.fit(X_train_scaled,Y_train)

  # get the feature_names
  feature_names=df.drop("diagnosis",1).columns[rfe.get_support()]

  return feature_names

rfe_features=run_rfe()

rfe_features

rfe_eval_df=evaluate_model_on_features(df[rfe_features],Y)

rfe_eval_df.index=['Recursive Filter Elimination']

results = results.append(rfe_eval_df)
results.head(n=10)

